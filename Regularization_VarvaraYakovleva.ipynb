{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Varvara Yakovleva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random as rnd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regLinPoli2.csv\") ##insert your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[[df.columns[-1]]], train_size=0.75)\n",
    "#print X_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I recommend that after manipulating data using pandas and before modelling to convert dataframes into arrays. This may avoid some headaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure for data standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This procedure is useful for classroom examples. For a real implementation you have to have a separete method \n",
    "# for transforming the production data so you can transform it as you get it with the fitted scaler\n",
    "## The procedure returns a standardized copy of the input data\n",
    "def normalize(X_train,X_test,Y_train,Y_test,do=True):\n",
    "\n",
    "    scale_X=preprocessing.StandardScaler()\n",
    "    scale_y=preprocessing.StandardScaler()\n",
    "    \n",
    "    train_X=np.copy(X_train)\n",
    "    train_y=np.copy(Y_train)\n",
    "    test_X=np.copy(X_test)\n",
    "    test_y=np.copy(Y_test)\n",
    "    if do:\n",
    "        scale_X.fit(train_X)\n",
    "        scale_y.fit(train_y)\n",
    "        train_X=scale_X.transform(train_X)\n",
    "        train_y=scale_y.transform(train_y)\n",
    "        test_X=scale_X.transform(test_X)\n",
    "        test_y=scale_y.transform(test_y)\n",
    "    return train_X,test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental regularized regression procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Transfer function\n",
    "def salida(w,X):\n",
    "    return X.dot(w[1:]) +w[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def entrena(X,y,w,la=0.0,eta=0.01):\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        error=y[i]-salida(w,X[i])\n",
    "        w[0]=w[0]+eta*(error)\n",
    "        w[1:]=w[1:]+eta*(error*X[i])-la*w[1:]\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcError(X,y,w,w0):\n",
    "    return np.mean((X.dot(w)+w0-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X,test_X,train_y,test_y=normalize(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=np.asarray([rnd.random() for i in range(1+len(train_X[0]))])\n",
    "for i in range(100):\n",
    "    w=entrena(train_X,train_y,w,la=0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533977604271\n",
      "0.703713982359\n"
     ]
    }
   ],
   "source": [
    "## flatten here to convert y from a matrix to a vector. Only 1 response variable\n",
    "print calcError(train_X,train_y.flatten(),w[1:],w[0])\n",
    "print calcError(test_X,test_y.flatten(),w[1:],w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## complexity = 1- lambda  x error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#divide train set into 5 subsets randomly\n",
    "index=np.array([1 if rnd.random() < 0.2 else 2 if rnd.random() < 0.4 else 3 if rnd.random() < 0.6 else 4 if rnd.random() < 0.8 else 5 for i in range(len(X_train))])\n",
    "\n",
    "X_test1=np.array(X_train)[index==1]\n",
    "Y_test1=np.array(Y_train)[index==1]\n",
    "X_test2=np.array(X_train)[index==2]\n",
    "Y_test2=np.array(Y_train)[index==2]\n",
    "X_test3=np.array(X_train)[index==3]\n",
    "Y_test3=np.array(Y_train)[index==3]\n",
    "X_test4=np.array(X_train)[index==4]\n",
    "Y_test4=np.array(Y_train)[index==4]\n",
    "X_test5=np.array(X_train)[index==5]\n",
    "Y_test5=np.array(Y_train)[index==5]\n",
    "\n",
    "#define future train sets\n",
    "X_train1=np.vstack((X_test2, X_test3, X_test4, X_test5))\n",
    "Y_train1=np.vstack((Y_test2, Y_test3, Y_test4, Y_test5))\n",
    "    \n",
    "X_train2=np.vstack((X_test1, X_test3, X_test4, X_test5))\n",
    "Y_train2=np.vstack((Y_test1, Y_test3, Y_test4, Y_test5))\n",
    "\n",
    "    \n",
    "X_train3=np.vstack((X_test2, X_test1, X_test4, X_test5))\n",
    "Y_train3=np.vstack((Y_test2, Y_test1, Y_test4, Y_test5))\n",
    "    \n",
    "X_train4=np.vstack((X_test2, X_test3, X_test1, X_test5))\n",
    "Y_train4=np.vstack((Y_test2, Y_test3, Y_test1, Y_test5))\n",
    "    \n",
    "X_train5=np.vstack((X_test2, X_test3, X_test4, X_test1))\n",
    "Y_train5=np.vstack((Y_test2, Y_test3, Y_test4, Y_test1))\n",
    "\n",
    "#define lambdas \n",
    "lam = [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.015, 0.02, 0.03, 0.04]\n",
    "lam = np.array(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each lambda have 5 trainings where 1 train set is a test set, calculate the error\n",
    "errlam = []\n",
    "for i in range(len(lam)):\n",
    "    \n",
    "    train_X1,test_X1,train_y1,test_y1=normalize(X_train1,X_test1,Y_train1,Y_test1)\n",
    "    \n",
    "    w=np.asarray([rnd.random() for k in range(1+len(train_X1[0]))])\n",
    "    for m in range(10):\n",
    "            w=entrena(train_X1,train_y1,w,la= lam[i])\n",
    "    err1 = calcError(test_X1,test_y1.flatten(),w[1:],w[0])\n",
    "    \n",
    "    \n",
    "    train_X2,test_X2,train_y2,test_y2=normalize(X_train2,X_test2,Y_train2,Y_test2)\n",
    "    \n",
    "    w=np.asarray([rnd.random() for k in range(1+len(train_X2[0]))])\n",
    "    for m in range(10):\n",
    "        w=entrena(train_X2,train_y2,w,la= lam[i])\n",
    "    err2 = calcError(test_X2,test_y2.flatten(),w[1:],w[0])\n",
    "    \n",
    "    \n",
    "    train_X3,test_X3,train_y3,test_y3=normalize(X_train3,X_test3,Y_train3,Y_test3)\n",
    "    \n",
    "    w=np.asarray([rnd.random() for k in range(1+len(train_X3[0]))])\n",
    "    for m in range(10):\n",
    "        w=entrena(train_X3,train_y3,w,la= lam[i])\n",
    "    err3 = calcError(test_X3,test_y3.flatten(),w[1:],w[0])\n",
    "    \n",
    "    \n",
    "    train_X4,test_X4,train_y4,test_y4=normalize(X_train4,X_test4,Y_train4,Y_test4)\n",
    "    \n",
    "    w=np.asarray([rnd.random() for k in range(1+len(train_X4[0]))])\n",
    "    for m in range(10):\n",
    "        w=entrena(train_X4,train_y4,w,la= lam[i])\n",
    "    err4 = calcError(test_X4,test_y4.flatten(),w[1:],w[0])\n",
    "    \n",
    "    \n",
    "    train_X5,test_X5,train_y5,test_y5=normalize(X_train5,X_test5,Y_train5,Y_test5)\n",
    "    \n",
    "    w=np.asarray([rnd.random() for k in range(1+len(train_X5[0]))])\n",
    "    for m in range(10):\n",
    "        w=entrena(train_X5,train_y5,w,la= lam[i])\n",
    "    err5 = calcError(test_X5,test_y5.flatten(),w[1:],w[0])\n",
    "    \n",
    "    errlam.append((err1+err2+err3+err4+err5)/float(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMiwkSZ0MC0lSJ8NCktTJsJAkdfp/qPshoTqNZp4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eb4e490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(1-lam, errlam, color = 'red')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"complexity (1-lam)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
